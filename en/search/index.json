[{"content":"If you know about Uniswap V2, you definitely know that its biggest advantage is ‚Äúfully automated,‚Äù and its biggest problem is also ‚Äúfully automated.‚Äù Once funds enter, they are mechanically distributed across the entire price range from 0 to ‚àû.\nThis is supposed to be fair, but extremely inefficient:\nMost of the time, assets are ‚Äúsleeping‚Äù far away from the current market price, nobody trades there, and no fees are generated.\nTherefore, Uniswap V3 proposed a revolutionary concept: Concentrated Liquidity.\nIt allows LPs to ‚Äúconcentrate‚Äù capital within the price range they consider appropriate so that ‚Äúactive money actually works.‚Äù\nI. What is Concentrated Liquidity: Background and the Problem It Solves The decentralized trading protocol Uniswap uses the automated market maker (AMM) model. Users don‚Äôt need to place orders or find counterparties ‚Äî simply deposit two tokens into a pool to become a liquidity provider. This model is very simple, but it also brings an unnoticed problem: most liquidity does not actually work.\nTo illustrate this, we need to review the mechanism of Uniswap v2.\n1. Traditional AMM: Constant Product and ‚ÄúFull Price Range‚Äù In v2‚Äôs constant product model, a trading pool maintains a formula:\nx ¬∑ y = k\nHere, x and y are the quantities of two assets in the pool, and k is a constant. No matter how the price fluctuates, this formula always holds.\nBut the model implicitly assumes:\nThe liquidity of the pool is distributed across the entire price range from 0 to ‚àû.\nTheoretically, no matter how high or low the price goes, the pool is ‚Äúready‚Äù to provide liquidity.\nThe problem: real prices never go to 0 or infinity.\nIn other words, liquidity is passively spread across a ridiculously wide range that will almost never be used.\n2. Liquidity Utilization Problems Distributing liquidity across an overly wide range results in a very direct consequence:\nMost capital is sleeping.\nIn reality, prices tend to fluctuate within a narrow band, so only funds inside that range actually participate in trades. Other funds are just lying around, consuming capital efficiency.\nThis leads to two impacts:\nFor traders, active depth is limited, causing higher slippage For LPs, although much capital is locked, the return is not proportional In other words:\nCapital utilization is low.\n3. Why Concentrated Liquidity Is Needed Uniswap v3 introduces Concentrated Liquidity, with the following core idea:\nLiquidity should be placed where actual trading happens.\nIf the price stays in a certain region for a long time, LPs can concentrate liquidity in that region instead of wasting it on extreme prices that might never occur.\nThe effects are significant:\nThe same capital provides deeper liquidity Price impact for large orders is reduced Fee revenue increases This essentially changes the AMM from ‚Äúbroad distribution‚Äù to ‚Äúlocally effective distribution.‚Äù\n4. Definition of Concentrated Liquidity Strictly speaking, Concentrated Liquidity means:\nLPs only provide liquidity within a self-defined price range \\([P_{lower}, P_{upper}]\\). Once price moves outside the range, the LP stops participating and stops earning fees.\nThat means each LP is no longer just part of a pool, but becomes a ‚Äúconditional liquidity position.‚Äù\nFrom the contract‚Äôs perspective, the large pool is divided into many segments, and liquidity is placed into each range. Whichever range trades happen within, LPs of that segment earn fees.\n5. What Problem Does It Actually Solve In one sentence:\nUse the same capital to obtain deeper effective liquidity.\nBut specifically, it improves three things:\nCapital Efficiency Lower Slippage Higher Fee Yield These all come from one fact: liquidity can finally be concentrated rather than being infinitely diluted.\n6. But It‚Äôs Not a Free Optimization Concentrated liquidity does not change the basic AMM logic but introduces a new dimension: price range.\nThis makes the LP role more strategic, similar to predicting price movement. Therefore, it also introduces a new risk:\nIf price moves out of the chosen range, the position becomes single-sided and stops earning. To earn more, LPs must take on more management and judgement ‚Äî a typical risk-return tradeoff.\nII. How Concentrated Liquidity Works 1. Inputs Required to Provide Liquidity Suppose we provide liquidity into an ETH/USDC pool, the contract requires:\nToken pair: ETH / USDC\nPrice range\nlower price example: 2000 USDC/ETH upper price example: 3000 USDC/ETH Amount of ETH or USDC provided\nIn other words, we‚Äôre telling the contract three things:\nI want to LP for ETH/USDC Within 2000‚Äì3000 I‚Äôm willing to deposit this amount of tokens 2. Which Token(s) Must Be Deposited Suppose current ETH/USDC price is 2500, then the system checks:\n2000 \u0026lt; 2500 \u0026lt; 3000 Meaning ‚Äúprice is inside the range.‚Äù\nThis is extremely important because it determines which assets we need to provide:\nThree situations Current Price Required Deposit Inside range Provide both ETH and USDC Below range Only USDC Above range Only ETH Why? Not strategy ‚Äî pure math: AMM models automatically bias towards one asset depending on price.\nSimply put, scarcity determines demand. At low price, the pool needs more USDC; at high price, more ETH.\n3. Understanding Liquidity (L) Although we deposit ETH/USDC, the contract records a variable L (liquidity unit).\nKey points:\nWe deposit assets Contract records L Earnings are proportional to L In short:\nL is our ‚Äúposition size‚Äù in that price range.\nThe amounts of ETH/USDC adjust automatically with price.\n4. Price Range Discretization We enter ranges in continuous price (e.g., 2000‚Äì3000), but internally the contract uses ticks.\nIt converts them to:\n\\(tick_{Lower}\\) \\(tick_{Upper}\\) Ticks discretize price boundaries.\nThe contract then stores only boundary updates:\nadd +L at \\(tick_{Lower}\\) subtract ‚ÄìL at \\(tick_{Upper}\\) Active liquidity at current price equals the sum of all netLiquidity values below the current tick.\nFor example, if \\(tick_{Lower}=100\\) and \\(tick_{Upper}=200\\), the contract records:\nnetLiquidity[100] += 10 netLiquidity[200] -= 10 If the current price tick is 150, the activeLiquidity equals the sum of all netLiquidity where tick \u0026lt; 150, which is 10.\nIf the current price tick is 205, then activeLiquidity equals the sum of all netLiquidity where tick \u0026lt; 205, which is 0.\nTherefore, when the price crosses these ticks, the system knows when to start and when to stop using our liquidity.\nWhy do we need to discretize price when storing ranges?\nIf we simply used linear segmentation, such as slicing the 2000‚Äì3000 range into 1000 parts, each worth 1 USDC, it would seem natural.\nBut what if the price range becomes 0.2‚Äì0.3 or even lower? If we still slice it into 1000 segments, each segment would become extremely small, and the overall scale would be highly uneven.\nFurthermore, real token prices can span multiple orders of magnitude, from 0.0000001 to 10,000,000, making uniform segmentation impossible.\nHow do we perform discretization?\nWe define that each tick corresponds to a price that is a fixed multiple \\(r\\) of the previous tick. Then, for \\(tick+1\\), the price \\(P_{tick+1}\\) satisfies:\n\\[ P_{tick+1} = P_{tick} \\times r \\]From which we derive:\n\\[ P_{tick} = P_0 \\times r^{tick} \\]If we set \\(P_0 = 1\\) and \\(r=1.0001\\), then:\n\\[ P_{tick} = 1.0001^{tick} \\]This means each tick movement corresponds to a 0.01% price change.\nNow we can represent any price using ticks:\n\\[ tick = \\log_{1.0001}(P) \\]For example:\n\\(P = 0.25\\) corresponds to \\(tick \\approx -13864\\)\n\\(P = 2500\\) corresponds to \\(tick \\approx 78244\\)\nThus, we obtain a uniform tick scale that works for arbitrary token prices (as long as they‚Äôre not negative ü§™)\n5. Storing Liquidity State When we add liquidity, the system issues an NFT that records:\nchosen price range (2000‚Äì3000) size of L accumulated fees claimable current fee status required for future fee calculations Therefore:\nThe LP action is no longer part of the pool itself, but an independent position recorded as an NFT.\n6. Position Changes When price is within the range:\nholds both ETH and USDC converts between the two as trades occur participates in matching and earns fees If price falls below 2000:\nposition becomes entirely USDC no longer provides liquidity or earns fees If price exceeds 3000:\nposition becomes entirely ETH also exits liquidity In other words:\nWhen ETH rises, the position becomes ETH-heavy; when ETH falls, it becomes USDC-heavy.\nThis behavior is not a strategy ‚Äî it is automatically done by the AMM logic.\n7. Fee Settlement When trades occur inside the range (2500 is inside), fees accumulate. Internally, the contract records fees in the feeGrowth variable.\nWhen withdrawing, the contract does two things:\nreturns current holdings (could be ETH+USDC or single-token) returns accumulated fees No need to manually claim‚Äîwithdrawal automatically settles everything.\nIII. Main Formula Derivations 1. Official Whitepapers v2: https://docs.uniswap.org/whitepaper.pdf\nv3: https://app.uniswap.org/whitepaper-v3.pdf\nv4: https://app.uniswap.org/whitepaper-v4.pdf\n2. Basic Formulas Virtual reserve curve (trading model):\n\\[ x \\times y = k \\tag{1} \\]Liquidity:\n\\[ L = \\sqrt{xy} \\tag{2} \\]Price:\n\\[ P = \\frac{y}{x} \\tag{3} \\]Effective reserve curve:\n\\[ (x+\\dfrac{L}{\\sqrt{p_{b}}})(y+L\\sqrt{p_{a}})=L^{2} \\tag{4} \\]2. Derivation of the Effective Reserve Curve As shown in Figure 1, the current price is at point c. Suppose the actual price movement range is \\([a,b]\\).\nWhen the price moves from c to a, the maximum pool consumption for token \\(y\\) is \\(y_{real}\\). Likewise, when price moves from c to b, the maximum pool consumption for token \\(x\\) is \\(x_{real}\\).\nTherefore, in theory, only \\(x_{real}\\) and \\(y_{real}\\) are required. All other funds are permanently unused, which also explains why the original xyk model has low capital efficiency.\nSo the question is: what should the effective reserve curve actually look like?\nAs shown in Figure 2, we begin deriving the effective reserve curve.\nFrom the following formulas:\n\\[ L^2 = xy \\\\ P = \\frac{y}{x} \\]For anyone who has attended junior high school mathematics, multiplying and dividing both sides of the equations easily yields:\n\\[ \\begin{aligned} x = \\dfrac{L}{\\sqrt{P}} \\\\ y = L\\sqrt{P} \\tag{4} \\end{aligned} \\]From Figure 1 we know:\n\\[ x = x_{real} + x_b \\\\ y = y_{real} + y_a \\]Substituting into the xyk model (1):\n\\[ (x_{real}+x_b)(y_{real}+y_a) = k = L^2 \\]Then substituting \\(x_b, y_a\\) using formula (4):\n\\[ (x_{real}+\\dfrac{L}{\\sqrt{P_{b}}})(y_{real}+L\\sqrt{P_{a}})=L^{2} \\]This is the final formula of the effective reserve curve.\n3. Calculating Liquidity Composition Changes After we provide liquidity, the contract starts performing trades. So how do we calculate the current allocation of assets inside our provided liquidity?\nBased on formula (4):\n\\[ \\begin{aligned} x=\\dfrac{L}{\\sqrt{p}} \\\\ y=L\\sqrt{P} \\tag{4} \\end{aligned} \\]Let:\n\\[ \\begin{aligned} S = \\sqrt{P} \\end{aligned} \\]Then:\n\\[ \\begin{aligned} x = \\dfrac{L}{S} \\\\ y = L S \\end{aligned} \\]Since L remains constant, differentiate with respect to S:\nFor x:\n\\[ x = \\frac{L}{S} \\Rightarrow dx = -L \\frac{1}{S^2} dS \\]For y:\n\\[ y = L S \\Rightarrow dy = L dS \\]So we have two important differential relationships:\n\\[ dx = -L \\frac{1}{S^2} dS,\\qquad dy = L dS \\]Suppose an LP‚Äôs effective price range is:\nLower price: \\(P_a\\), corresponding to \\(S_a = \\sqrt{P_a}\\) Upper price: \\(P_b\\), corresponding to \\(S_b = \\sqrt{P_b}\\) Consider only the \\(token_y\\) change\nInside the range, when S increases from \\(S_a\\) to \\(S_b\\):\n\\[ dy = L dS \\]Integrate S from \\(S_a\\) to \\(S_b\\):\n\\[ \\Delta y = \\int_{S_a}^{S_b} L\\, dS = L (S_b - S_a) = L(\\sqrt{P_b} - \\sqrt{P_a}) \\]This is the total amount of \\(token_y\\) corresponding to the entire interval \\([P_a, P_b]\\):\n\\[ amount_y = L(\\sqrt{P_b} - \\sqrt{P_a}) \\]Consider only \\(token_x\\)\n\\[ dx = -L \\frac{1}{S^2} dS \\]Note that x decreases as S increases (price rises ‚Üí token_x decreases). We want the total amount in absolute value:\n\\[ \\Delta x = \\int_{S_a}^{S_b} L \\frac{1}{S^2} dS \\]Compute:\n\\[ \\int \\frac{1}{S^2} dS = -\\frac{1}{S} \\]Thus:\n\\[ \\Delta x = L\\left[-\\frac{1}{S}\\right]_{S_a}^{S_b} = L\\left(-\\frac{1}{S_b} + \\frac{1}{S_a}\\right) = L\\left(\\frac{1}{S_a} - \\frac{1}{S_b}\\right) \\]Substitute \\(S = \\sqrt{P}\\):\n\\[ amount_x = L\\left(\\frac{1}{\\sqrt{P_a}} - \\frac{1}{\\sqrt{P_b}}\\right) \\]This is the interval formula for \\(token_x\\).\nThe above derivation covers total x/y in the entire interval \\([P_a, P_b]\\). But the actual situation depends on where the current price lies:\nCase A: Current price inside the range \\((P_a \u003c P \u003c P_b)\\)\nThe position holds ‚Äúpart token0 and part token1‚Äù:\nFor \\(token_x\\), effective interval is [P, P_b]:\n\\[ amount_x = L\\left(\\frac{1}{\\sqrt{P}} - \\frac{1}{\\sqrt{P_b}}\\right) \\] For \\(token_y\\), effective interval is [P_a, P]:\n\\[ amount_y = L(\\sqrt{P} - \\sqrt{P_a}) \\] Case B: Price below the range \\((P \\le P_a)\\)\nThe position has not ‚Äúmoved upward yet,‚Äù and is entirely in \\(token_x\\):\n\\[ amount_x = L\\left(\\frac{1}{\\sqrt{P_a}} - \\frac{1}{\\sqrt{P_b}}\\right) \\\\ amount_y = 0 \\]Case C: Price above the range \\((P \\ge P_b)\\)\nThe position has ‚Äúfully moved upward,‚Äù and is entirely \\(token_y\\):\n\\[ amount_x = 0 \\\\ amount_y = L(\\sqrt{P_b} - \\sqrt{P_a}) \\]4. Calculating the Actual Trading Price Now that we understand the trading principle and core formulas, when preparing to swap tokens through the pool, the assets we input will also affect the ratio between pool assets. Since \\(P=\\dfrac{y}{x}\\) is only a theoretical price, how do we calculate the actual execution price? For example, how many USDC can 1 ETH be swapped for?\nWhen we put \\(\\Delta x\\) ETH into the pool, USDC in the pool decreases by \\(\\Delta y\\), and the corresponding price moves from \\(P_0\\) down to \\(P_1\\). So we have:\n\\[ \\begin{aligned} \\Delta x \u0026= L\\left(\\frac{1}{\\sqrt{P_1}} - \\frac{1}{\\sqrt{P_0}}\\right) = L\\left(\\frac{1}{S_1} - \\frac{1}{S_0}\\right) \\Rightarrow S_1 = \\frac{1}{\\dfrac{\\Delta x}{L} + \\dfrac{1}{S_0}} \\\\ \\Delta y \u0026= L(\\sqrt{P_0} - \\sqrt{P_1}) = L(S_0 - S_1) = L\\left(S_0 - \\frac{1}{\\dfrac{\\Delta x}{L} + \\dfrac{1}{S_0}}\\right) \\end{aligned} \\]where L is the active liquidity in the current price segment.\nIf the trade size is large and crosses multiple ticks, split the swap into segments and apply the same method for each interval, summing all the Œîy values across each segment.\n","date":"2025-08-02T14:59:56+08:00","permalink":"https://yearsuns-github-io.vercel.app/en/p/a-deep-dive-into-the-fundamental-principles-of-uniswaps-concentrated-liquidity/","title":"A Deep Understanding of the Fundamental Principles of Uniswap‚Äôs Concentrated Liquidity"},{"content":" XYK means: put a pair of assets into a ‚Äúpool‚Äù, and require that the product of the two asset amounts always stays equal: x * y = k. All swaps must follow this rule, and therefore price, slippage, yield and risk all naturally come from this formula.\nLet‚Äôs walk through the math step by step.\n1. Traditional Trading: Why Do We Need an Order Book? In traditional exchanges, the core mechanism is the order book:\nA places a buy order at 100 for 1 ETH B places a sell order at 101 for 2 ETH The system matches orders and completes the trade This design has several characteristics:\n1. Requires professional market makers Without someone providing orders, ordinary traders cannot trade Market makers must watch the market and continuously update orders 2. Requires a centralized matching engine Run by the exchange You have to trust the intermediary 3. Ordinary users cannot participate in market-making easily Hard to provide liquidity Most profits go to institutions For blockchain, which emphasizes open participation, this is too centralized.\n2. AMM: Turning Market Making into a Liquidity Pool The innovation of AMM (Automated Market Maker) is transforming trading from order matching into a liquidity pool that anyone can join.\nA liquidity pool holds two assets (e.g., ETH and USDT) and follows:\nx * y = k This is the XYK constant product market maker model.\nWhen someone buys ETH with USDT, ETH decreases and USDT increases, while keeping the product constant.\nAMM replaces the order book:\nno buy/sell orders no professional market makers no centralized matching engine anyone can join So essentially:\nAMM = liquidity pool + mathematical rule\nPrice, slippage and liquidity depth all follow from this.\n3. How Is Price Determined? Example:\nPool state:\nETH x = 100 USDT y = 10000 Then the price is naturally:\nprice = y / x = 10000 / 100 = 100 USDT Key points:\nPrice is not quoted manually Price changes automatically with pool state External arbitrage aligns the pool price to market price So in AMM:\nPrice = asset ratio in pool\n4. How Do Trades Change Price? Initial State x = 100 ETH y = 10000 USDT k = 1,000,000 P‚ÇÄ = 100 A user wants to spend 1000 USDT to buy ETH.\nTransaction rule Must satisfy x * y = k before and after the swap\nAfter the swap User adds:\nŒîy = +1000 y‚ÇÇ = 11000 x‚ÇÇ = 1,000,000 / 11000 ‚âà 90.909 Œîx ‚âà 9.091 Average price ‚âà 110 Final price ‚âà 121\nYou observe:\nAverage paid ‚âà 110 Final price ‚âà 121 Initial price = 100 That feeling of:\n‚ÄúI buy ‚Üí the price jumps!‚Äù\nThat is slippage.\n5. Slippage: Not a Fee, But Price You Push Higher Slippage is not a fee:\nYou moved the price by trading You are literally buying along the curve from cheap ‚Üí expensive. Bigger trades cause more slippage.\n6. Why Bigger Pools Have Lower Slippage? Compare:\nSmall pool: 100 / 10000 Price moves 100 ‚Üí 121\nBig pool: 1000 / 100000 Price moves 100 ‚Üí 102\nConclusion:\nMore liquidity ‚Üí milder price curve ‚Üí lower slippage\nIt\u0026rsquo;s like:\na basin vs. a lake adding a bucket changes the level much more in a basin 7. What Exactly Is Liquidity? Liquidity = actual asset amounts in the pool\nmore liquidity ‚Üí flatter curve ‚Üí stable prices less liquidity ‚Üí steep curve ‚Üí price impact increases Anyone can provide liquidity, therefore:\nMarket-making becomes open\n8. How Do You Join as a Liquidity Provider? Pool state:\nx = 100 ETH y = 10000 USDT Price = 100 USDT/ETH\nTo add liquidity, you must deposit proportionally:\nadd 1 ETH plus 100 USDT Otherwise you change the price.\nYou receive LP tokens representing your share.\nWhen you withdraw, you take a share of the pool, not exactly what you put in.\nThis is important for understanding impermanent loss.\n9. How Do LPs Earn Fees? Each trade pays a small fee (e.g., 0.3%), and this fee:\ndoes NOT go to ‚Äúthe platform‚Äù goes into the pool distributed to LPs Think of it as:\nTraders use your assets, and you charge toll fees\nLP earnings:\ntrading fees token incentives 10. Impermanent Loss LPs earn fees but face impermanent loss.\nExample pool:\n1 ETH + 100 USDT You add:\n1 ETH + 100 USDT Pool:\n2 ETH + 200 USDT (You own 50%) If ETH price falls, the pool becomes:\n4 ETH + 100 USDT You withdraw:\n2 ETH + 50 USDT = 100 USDT value You deposited value: 200 You withdraw value: 100\nYou lose value because:\npool moved toward the depreciating asset arbitrage takes the increasing asset out The pool automatically rebalances toward cheaper assets.\n11. What Problems Does XYK Solve? No order book Price determined algorithmically Anyone can become a market maker Infrastructure becomes public and open 12. Limitations \u0026amp; Evolution XYK drawbacks Large slippage ‚Üí specialized stable-swap curves (Curve) Poor capital efficiency ‚Üí concentrated liquidity (Uniswap v3) Impermanent loss ‚Üí LP bears volatility risk Still:\nXYK is the entrance door to AMM design\nUnderstanding XYK makes everything else easier.\n13. The One Simple Formula Back to:\nx * y = k From this follows:\nprice: P = y / x slippage liquidity depth LP revenue impermanent loss XYK is the F = ma of DeFi:\ndeceptively simple, yet the foundation of decentralized trading.\n","date":"2025-07-16T14:59:56+08:00","permalink":"https://yearsuns-github-io.vercel.app/en/p/a-deep-dive-into-the-fundamental-principles-of-uniswaps-xyk-model/","title":"A Deep Dive into the Fundamental Principles of Uniswap‚Äôs XYK Model"},{"content":"1. Introduction: Passwords Are the Last Line of Defense in the Digital World In the entire ecosystem of internet security, passwords are the most common yet also the most fragile component. Almost all services we use daily‚Äîemail, online banking, social platforms, games, forums‚Äîrely on passwords to authenticate user identity.\nA password is essentially a weak credential:\nIt cannot prove who the user really is‚Äîit only proves that they ‚Äúknow a certain secret.‚Äù Once this secret is leaked, an attacker can completely impersonate you. Modern cyberattacks are frequent and diverse. A single ordinary password leak often results in multiple accounts across different platforms being compromised. To defend against these threats, we must strengthen both the transmission stage and the storage stage.\nThis article builds from fundamental concepts and gradually develops a complete, modern password security system.\n2. Why Are Passwords So Dangerous? At first glance, a password is just a string composed of characters. But the damage caused by a leaked password is far more severe than it seems, mainly for two reasons.\n2.1 Risk 1: Leakage During Transmission From the moment a user enters a password until it reaches the server, the data passes through:\nThe browser Local DNS resolution OS network stack Routers ISP backbone Server load balancers If any part of this chain is compromised, the password could be intercepted.\nIn theory, HTTPS solves the ‚Äúeavesdropping problem.‚Äù But reality is more complex. Common risks include:\nMalware installing fake root certificates (classic MITM strategy) Internal corporate/school networks performing TLS inspection Public Wi-Fi conducting ARP spoofing and re-signing HTTPS certificates Browser extensions injecting malicious scripts to read user input ‚ÄúNetwork optimization‚Äù software adding hidden interception modules Enterprise gateways performing SSL inspection (legal but unsafe) In other words:\nYou cannot assume the user‚Äôs device or network environment is always secure.\nTherefore, there is room to improve the security of transmission.\n2.2 Risk 2: Server-side Leakage Most leaks occur on the server side. Common scenarios include:\nDatabase breaches (most common) Passwords accidentally printed in logs Developers outputting passwords during debugging Unencrypted backups mistakenly exposed to the public Third-party monitoring tools capturing sensitive fields Vulnerabilities (SQL injection, RCE) exposing the database Internal misuse of privileges by operations staff If the server stores plaintext passwords, the consequences are catastrophic:\nAll user passwords are exposed Accounts on other websites are compromised due to password reuse If attackers access a user‚Äôs email, the impact escalates further Therefore, the server must ensure that even if a breach occurs, attackers cannot obtain the real passwords.\n3. How Should Passwords Be Safely Transmitted Over the Internet? 3.1 The Most Straightforward Approach: Send the Password Directly Over HTTPS This is the default method used by most websites today:\nBrowser ‚Äî‚ÄîHTTPS‚Äî‚Äî\u0026gt; Server Advantages:\nSimple Mature Fast Compatible with everything The drawback is:\nIt places all risk on the reliability of TLS.\nIf TLS is compromised by a MITM attack, the password is exposed.\nThus, some propose hashing the password on the client side first.\n4. Front-end Hashing: Risks Reduced and Risks Not Reduced The core idea of front-end hashing is:\nEven if the transmission is intercepted, the attacker does not get the real password.\nAssume:\nP = user password H1 = hash(P) The browser sends H1 instead of P.\n4.1 What Can Front-end Hashing Protect Against? Prevents MITM from obtaining the real password Prevents plaintext password leakage through server logs/monitoring Attackers cannot use H1 to log in to the user‚Äôs accounts on other websites Even if users reuse passwords elsewhere, a breach of your site won‚Äôt cascade to others (very important) The server never touches plaintext passwords (a simple form of zero-knowledge authentication) Front-end hashing provides:\n‚ÄúEven if your website is compromised, attackers still cannot learn users‚Äô real passwords for other services.‚Äù\nTraditional approaches cannot offer this.\n4.2 What Can Front-end Hashing Not Protect Against? Attackers can directly use H1 to log in to your website (you treat it as the credential) Keyloggers / infected devices still capture P Hashes without challenge are vulnerable to replay attacks HTTPS is still required‚Äîhashes themselves must be encrypted In short:\nFront-end hashing reduces damage but does not eliminate risk.\n4.3 Is Front-end Hashing Necessary? In practice, it is an optional but clearly beneficial enhancement.\nWhen implemented properly (with challenges to prevent replay), front-end hashing creates a dual defense:\nTLS ensures transport security Hashing reduces cross-site password reuse impact High-security systems (banks, enterprise platforms, developer services) often use such mechanisms.\n5. How Should Servers Store Passwords? Now to the core of password engineering:\nPasswords must never appear in plaintext‚Äîeven inside the server.\nIndustry standards involve three key elements:\nHash Salt Slow hash 5.1 Hashing: Making It Irreversible A good hashing function must:\nHave extremely low collision probability Change output drastically when input changes slightly (avalanche effect) Make it impossible to reverse the input Servers store:\nH = hash(P) If the database leaks, attackers cannot directly obtain the password.\n5.2 Salt: Preventing Rainbow Tables and Mass Cracking Without salt, users with the same weak passwords produce identical hashes. Attackers can:\nUse precomputed rainbow tables Test common passwords once to crack many accounts By adding a random salt:\nH = hash(P + salt) Now:\nTwo users with ‚Äú123456‚Äù have completely different hashes Rainbow tables become useless Attackers must brute-force each user individually (massively increasing cost) Salt must be:\nLong enough (‚â•16 bytes) Random (CSPRNG) Unique per user Stored in plaintext (not encrypted) 5.3 Slow Hashing: Truly Increasing the Cost of Attacks Algorithms like SHA256 are far too fast. Modern GPUs can compute billions of SHA256 hashes per second.\nMeaning:\nEven with salt, SHA256-stored passwords can often be cracked quickly.\nThus, we must use slow hashing algorithms designed specifically for password storage:\nAlgorithm Characteristics bcrypt Classic, mature scrypt GPU-resistant, high memory use Argon2 (recommended) Winner of password hashing competition; tunable CPU/memory/parallelism Slow hashing is not about ‚Äústronger hashing‚Äù; it\u0026rsquo;s about:\nMaking each guess expensive so attackers cannot perform massive brute-force attacks.\nLogin delays are negligible:\nUsers log in infrequently Each slow-hash costs only tens of milliseconds Attackers cannot scale up computations the same way 6. Dual Protection: Front-end Hash + Back-end Slow Hash Combined:\nP ‚Üí H1 = hash1(P) ‚Üí (transmission) ‚Üí H2 = bcrypt(H1 + salt) Dual-layer benefits:\nMITM capturing H1 cannot use it on other sites Database leaks revealing H2 are still hard to crack Server never touches plaintext passwords Logs and monitoring systems cannot leak P This ‚Äúfront-end hash + back-end slow hash‚Äù model is used in high-security environments to reduce cascade risks.\n7. The Replay Attack Problem of Front-end Hashing and Its Solution If front-end hashing is simply:\nH1 = hash(P) An attacker who intercepts H1 can replay it indefinitely‚Äîalmost identical to stealing the real password.\nSolution: Use a random challenge. 7.1 Complete Workflow User opens login page The server generates a challenge:\nchallenge = random string Browser computes:\nH1 = hash(P + challenge) Server verifies:\nbcrypt(H1 + salt) == stored_hash 7.2 Benefits H1 is different every time (challenge varies) Intercepted H1 cannot be reused MITM value decreases Server does not need to store challenge‚Äîjust verify once and discard 7.3 Common Engineering Issues Challenge must not be cached (use no-cache) Must be long enough (‚â•16 bytes) Front-end must use secure hash (SHA256 or higher) Still requires HTTPS (challenge itself can be intercepted otherwise) 8. Additional Important Practices (Often Overlooked) 8.1 Never Email Users Their Passwords Sending a new password via email is extremely dangerous. Correct process:\nSend a password reset link Link contains a one-time token User must set a new password 8.2 Do Not Allow Weak Passwords Weak passwords are exponentially easier to crack:\n123456 password qwerty User phone numbers User birthdays Use:\nBlacklists of common passwords (top 10k) Length policies (‚â•12 chars) Encouragement of password managers 8.3 Multi-factor Authentication (MFA / 2FA) Passwords are only the first layer. A second factor dramatically reduces attack success rates:\nTOTP (Google Authenticator) SMS codes (weaker, but still useful) Hardware keys (FIDO2 / U2F) 8.4 Account Protection Features Lockouts after multiple failed attempts Suspicious-login email alerts Unusual IP/UA verification steps Recent login activity logs for user review 8.5 Password Breach Checks (HIBP API) Many large websites check whether:\nA user\u0026rsquo;s chosen password appears in known breach databases (like HaveIBeenPwned) This significantly reduces risk from weak password reuse.\n9. Goals of a Modern Password Security System With all steps combined, a modern password system should ensure:\n9.1 Secure Transmission Use HTTPS Optional front-end hashing to prevent cascading leaks Challenge-based anti-replay 9.2 Secure Storage Never store plaintext passwords Unique salt per user Use slow hashing algorithms 9.3 Account Protection Strong password policies MFA Anomaly detection Password leak comparison No sensitive info in logs The final objective:\nEven if the entire server is compromised, attackers still cannot obtain any user\u0026rsquo;s real password.\n","date":"2025-06-29T14:59:56+08:00","permalink":"https://yearsuns-github-io.vercel.app/en/p/how-passwords-should-be-safely-transmitted-and-stored/","title":"How Passwords Should Be Safely Transmitted and Stored"}]